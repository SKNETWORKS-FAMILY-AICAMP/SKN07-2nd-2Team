{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./SKN07-2nd-2Team/SKN07-2nd-2Team/df_encoding.csv\")\n",
    "data = pd.DataFrame(data)\n",
    "data.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49752, 56)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['Churn']).values\n",
    "y = data['Churn'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data 에서 column 들 중 X, Churn을 y 로 둬....? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화 (특징들을 스케일링)\n",
    "scaler = StandardScaler()  # 데이터 정규화를 위한 StandardScaler 사용\n",
    "data = scaler.fit_transform(data)  # 데이터를 평균 0, 표준편차 1로 변환\n",
    "\n",
    "# 학습 데이터(60%), 나머지 데이터(40%) 나누기\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "# 테스트 데이터(20%)와 검증 데이터(20%) 나누기\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# 데이터를 PyTorch 텐서 형식으로 변환\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)  # 훈련 데이터\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)  # 타겟 데이터 (이진 분류이므로 2D 텐서로 변환)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)  # 테스트 데이터\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)  # 타겟 데이터(이진 분류이므로 2D 텐서로 변환)\n",
    "X_val_tensor = torch.tensor(X_train, dtype=torch.float32) # 검증 데이터터\n",
    "y_val_tensor = torch.tensor(X_train, dtype=torch.float32).view(-1, 1)  # 타겟 데이터(이진 분류이므로 2D 텐서로 변환)\n",
    "\n",
    "\n",
    "# DataLoader로 배치 처리 (훈련 데이터, 테스트 데이터)\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)  # 훈련 데이터셋 생성\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)  # 테스트 데이터셋 생성\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=64, shuffle=True)  # 훈련 데이터셋에 배치 크기 설정, 데이터를 섞음\n",
    "test_dl = DataLoader(test_data, batch_size=64, shuffle=False)  # 테스트 데이터셋에 배치 크기 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 모델 정의\n",
    "class tele_churn_predict(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(tele_churn_predict, self).__init__()\n",
    "        # 개의 입력 특징을 받아들이는 첫 번째 Fully Connected Layer\n",
    "        self.fc1 = nn.Linear(56, 32)  # 개의 입력 특징\n",
    "        self.fc2 = nn.Linear(32, 16)  # 32개의 출력에서 16개로 변환\n",
    "        self.fc3 = nn.Linear(16, 1)  # 16개의 출력에서 1개의 생존 확률 값으로 변환\n",
    "        self.sigmoid = nn.Sigmoid()  # 생존 확률을 0과 1 사이로 변환하기 위한 Sigmoid 함수\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.fc1(x))  # 첫 번째 레이어 후 ReLU 활성화 함수\n",
    "        x = nn.ReLU()(self.fc2(x))  # 두 번째 레이어 후 ReLU 활성화 함수\n",
    "        x = self.fc3(x)  # 세 번째 레이어\n",
    "        x = self.sigmoid(x)  # 출력값을 확률로 변환\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스화\n",
    "model = tele_churn_predict()\n",
    "# 손실 함수와 옵티마이저 설정\n",
    "loss_fn = nn.BCELoss()  # 이진 분류 문제이므로 Binary Cross Entropy 손실 함수 사용\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam 옵티마이저 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.6220, Accuracy: 0.7043\n",
      "Epoch 2/20, Loss: 0.5932, Accuracy: 0.7132\n",
      "Epoch 3/20, Loss: 0.5886, Accuracy: 0.7140\n",
      "Epoch 4/20, Loss: 0.5866, Accuracy: 0.7151\n",
      "Epoch 5/20, Loss: 0.5841, Accuracy: 0.7162\n",
      "Epoch 6/20, Loss: 0.5827, Accuracy: 0.7162\n",
      "Epoch 7/20, Loss: 0.5819, Accuracy: 0.7172\n",
      "Epoch 8/20, Loss: 0.5808, Accuracy: 0.7172\n",
      "Epoch 9/20, Loss: 0.5805, Accuracy: 0.7180\n",
      "Epoch 10/20, Loss: 0.5789, Accuracy: 0.7182\n",
      "Epoch 11/20, Loss: 0.5788, Accuracy: 0.7176\n",
      "Epoch 12/20, Loss: 0.5785, Accuracy: 0.7193\n",
      "Epoch 13/20, Loss: 0.5772, Accuracy: 0.7192\n",
      "Epoch 14/20, Loss: 0.5774, Accuracy: 0.7195\n",
      "Epoch 15/20, Loss: 0.5763, Accuracy: 0.7198\n",
      "Epoch 16/20, Loss: 0.5753, Accuracy: 0.7201\n",
      "Epoch 17/20, Loss: 0.5753, Accuracy: 0.7211\n",
      "Epoch 18/20, Loss: 0.5755, Accuracy: 0.7192\n",
      "Epoch 19/20, Loss: 0.5734, Accuracy: 0.7208\n",
      "Epoch 20/20, Loss: 0.5737, Accuracy: 0.7218\n"
     ]
    }
   ],
   "source": [
    "# 훈련 루프\n",
    "num_epochs = 20  # 훈련할 에포크 수 설정\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 모델을 훈련 모드로 설정\n",
    "    total_loss = 0  # 손실을 누적할 변수\n",
    "    correct = 0  # 정확도를 계산할 변수\n",
    "    \n",
    "    for X_batch, y_batch in train_dl:\n",
    "        optimizer.zero_grad()  # 기울기 초기화\n",
    "        output = model(X_batch)  # 순전파: 배치 데이터를 모델에 통과시켜 예측값 생성\n",
    "        loss = loss_fn(output, y_batch)  # 손실 계산\n",
    "        loss.backward()  # 역전파\n",
    "        optimizer.step()  # 옵티마이저로 파라미터 업데이트\n",
    "        \n",
    "        total_loss += loss.item()  # 손실값 누적\n",
    "        predicted = (output > 0.5).float()  # 예측값이 0.5보다 크면 생존, 작으면 사망\n",
    " \n",
    "        correct += (predicted == y_batch).sum().item()  # 정확도 계산\n",
    " # 에포크마다 손실과 정확도 출력\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_dl):.4f}, Accuracy: {correct/len(train_dl.dataset):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "pytorch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
